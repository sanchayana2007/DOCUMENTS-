Python Basics:
================================================================================================================
code practice:
http://www.cse.msu.edu/~cse231/PracticeOfComputingUsingPython/

http://showmedo.com/learningpaths/12/view#id5  (BEST1)
http://www.saltycrane.com/blog/tag/python/

Installation:
+++++++++++++++++
C:\Python33

Edit the path and add the python in the path to launch it fromany place 

Python is an Interpretted language
++++++++++++++++++++++++++++++++++
Python and LUA are handled quite differently—interpreted rather than compiled. When you run a Python program 
(a file with an extension of .PY), it is not compiled, it is run. You could insert syntax errors into a function
in Python and unless that function is called, Python will never complain about the errors!


# Funny syntax error example

# Bad function!
def ErrorProne():

    printgobblegobble("Hello there!")

print("See, nothing bad happened. You worry too much!")

There is no function called printgobblegobble() in Python or in this program, so that should have generated an error! 
Here is the output:


See, nothing bad happened. You worry too much!


Python 3.x:
class MyClass(object): = new-style class
class MyClass: = new-style class (implicitly inherits from object)

Python 2.x:
class MyClass(object): = new-style class
class MyClass: = OLD-STYLE CLASS
ew style objects have a different object model to classic objects, and some things won't work properly with old style objects, for instance, super(), @property and descrpnt
Explanation:

OOPS in python :
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Here is an example:


class Bug(object):
    legs = 0
    distance = 0

    def __init__(self, name, legs):
        self.name = name
        self.legs = legs

    def Walk(self):
        self.distance += 1

    def ToString(self):
        return self.name + " has " + str(self.legs) + " legs" + \
            " and taken " + str(self.distance) + " steps."

-----------------------------------------------------------------
Polymorphism:
The term polymorph means “many forms” or “many shapes”, so polymorphism is the ability to take many forms or shapes.
In the context of a class, this means we can use methods with many shapes—that is, many different sets of parameters.
In Python, we can use optional parameters to make a method more versatile. The constructor of our new Bug class can 
be transformed with the use of optional parameters like so:


    def __init__(self, name="Bug", legs=6):
        self.name = name
        self.legs = legs


--------------------------------------------------------------------------------------
Data Hiding (Encapsulation):


access or change the distance variable (which we would assume is private, even though it isn’t):


    def GetDistance(self):
       return p_distance

    def SetDistance(self, value):
        p_distance = value

From a data hiding point of view, you could rename distance to p_distance (making it appear to be a private variable), and then access it using these two methods. That is, if data hiding is important in your program.

Implementing a Private Function (Workaround method)
-------------------------------------------------------------
import re
import inspect

class MyClass :

    def __init__(self) :
        pass

    def private_function ( self ) :
        try :
            function_call = inspect.stack()[1][4][0].strip()

            # See if the function_call has "self." in the begining
            matched = re.match( '^self\.', function_call )
            if not matched :
                print 'This is Private Function, Go Away'
                return
        except :
            print 'This is Private Function, Go Away'
            return

        # This is the real Function, only accessible inside class #
        print 'Hey, Welcome in to function'

    def public_function ( self ) :
        # i can call private function from inside the class
        self.private_function()

### End ###






--------------------------------------------------------------------------------------
Inheritance:

Python supports inheritance of base classes. When a class is defined, the base class is included in parentheses:


class Car(Vehicle):

In addition, Python supports multiple inheritance; that is, more than one parent or base class can be inherited from
in a child class. For example:


class Car(Body,Engine,Suspension,Interior):

As long as the variables and methods in each parent class do not conflict with each other, the new child class can 
access them all without incident. But, if there are any conflicts, the conflicted variable or method is used from the 
parent that comes first in the inheritance ordering.


Use of super() to resolve any confuiosns in polymorphism
class Point():
    x = 0.0
    y = 0.0

    def __init__(self, x, y):
        self.x = x
        self.y = y
        print("Point constructor")



class Circle(Point):
    radius = 0.0

    def __init__(self, x, y, radius):
        super().__init__(x,y)
        self.radius = radius
 
 c = Circle(100,100,50)
 
 Output :
 
 Point constructor
Circle constructor


--------------------------------------------------------------------------------------
Object declaration :

A = Classname(22,22)

Calling the function is same as C++ 

A.fumc("dewded",12)

--------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------


variables and values are REFERENCES
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Everything is  reference of an Object except the variables user declares
f you're used to most traditional languages, you have a mental model of what happens in the following sequence:

a = 1
a = 2
You believe that a is a memory location that stores the value 1, then is updated to store the value 2. 
That's not how things work in Python. Rather, a starts as a reference to an object with the value 1,
then gets reassigned as a reference to an object with the value 2. Those two objects may continue to 
coexist even though a doesn't refer to the first one anymore; in fact they may be shared by any number
of other references within the program.

Value passing in a function is non mutable :
---------------------------------------------
When you call a function with a parameter, a new reference is created that refers to the object passed in. 
This is separate from the reference that was used in the function call, so there's no way to update that reference
 and make it refer to a new object. In your example:

    self.variable = 'Original'
    self.Change(self.variable)

def Change(self, var):
    var = 'Changed'
self.variable is a reference to the string object 'Original'. When you call Change you create a second reference
 var to the object. Inside the function you reassign the reference var to a different string object 'Changed',
 but the reference self.variable is separate and does not change.
 
 What is Happening here in terms of C++ terminology is
 ****************************************
 int& xRef = x;
	int& zRef = z;
	zRef = xRef; // Assigns values, not references
 ***************************************
 So over here var and 'changed' are two seperate references and now var value is equal to the 'changed' reference
 value.
 
The only way around this is to pass a mutable object. Because both references refer to the same object, any 
changes to the object are reflected in both places.

    self.variable = ['Original']
    self.Change(self.variable)

def Change(self, var):
    var[0] = 'Changed'

Now in this condition as var is a reference we are assigning the addresesss refered by var[0] to 'Changed' value 
So this willl refelect on self.variable also


Python Associations:
=================================================================================================================

The associations for python are 
1) tuple :
------------------
 It is a Immutable List and its fast in retriving and all it can be termed as an array
 A tuple is a sequence of immutable Python objects. Tuples are sequences, just like lists. The only difference is that 
 
 1) tuples can't be changed i.e., tuples are immutable 
 2) tuples use parentheses and lists use square brackets.

 tup1 = ('physics', 'chemistry', 1997, 2000);
 del tup; // delete tuples
	Empty and single tuples :
============================
	empty tuple is written as two parentheses containing nothing:
	tup1 = ();

To write a tuple containing a single value you have to include a comma, even though there is only one value:
	tup1 = (50,);
Like string indices, tuple indices start at 0, and tuples can be sliced, concatenated and so o
 
 
Updating Tuples: 
****************
# So let's create a new tuple as follows if you wana add something to tup1 make tup2 and concatenate in tup3
	tup3 = tup1 + tup2;
		print tup3;
 
Because tuples are sequences, indexing and slicing work the same way for tuples as they do for strings. Assuming following input:

	L = ('spam', 'Spam', 'SPAM!')
 

Python Expression	Results	 Description
	L[2]	'SPAM!'	Offsets start at zero
	L[-2]	'Spam'	Negative: count from the right
	L[1:]	['Spam', 'SPAM!']	Slicing fetches sections

 
2)List : Comprehension

---------------
The list is a most versatile datatype available in Python  Good thing about a list is that items in a list need not all have the same type.
Creating a list is putting different comma-separated values between squere brackets. For example:

list1 = ['physics', 'chemistry', 1997, 2000];
Basic List Operations:
Lists respond to the + and * operators much like strings; they mean concatenation and repetition here too, except that the result is a new list, not a string.

In fact, lists respond to all of the general sequence operations we used on strings in the prior chapter.

Python Expression	Results	 Description
----------------------------------------------
len([1, 2, 3])	3	Length
[1, 2, 3] + [4, 5, 6]	[1, 2, 3, 4, 5, 6]	Concatenation
['Hi!'] * 4	['Hi!', 'Hi!', 'Hi!', 'Hi!']	Repetition
3 in [1, 2, 3]	True	Membership
for x in [1, 2, 3]: print x,	1 2 3	Iteration

list[:-1]  Gives the list except the last one element Splicing


Unique Python use of list:
--------------------------

1. Filter a number range
[x for x in range(1,1000) if x % 3 == 0 or x % 5 == 0]


2. square up a list 
a = [1,2,3]
b= [ i **2 for  i in a]

2. Reverse a list 
g = "abcd"
g[::-1]
>> dcba

It starts from the end and prints every element 
g[::-2]
>> db
It starts from the end and prints every next element  element

Use of enumerate
-------------------------------------
refactored in a list comprehension like this:
>>> def _treatment(pos, element):
... return '%d: %s' % (pos, element)
...
>>> seq = ["one", "two", "three"]
>>> [_treatment(i, el) for i, el in enumerate(seq)]
['0: one', '1: two', '2: three']


 
3) Dictionaries :
-------------------
A dictionary is mutable and is another container type that can store any number of Python objects,
including other container types. Dictionaries consist of pairs (called items) of keys and their
corresponding values.

Python dictionaries are also known as associative arrays or hash tables. The general syntax of a
dictionary is as follows:

dict = {'Alice': '2341', 'Beth': '9102', 'Cecil': '3258'}
You can create dictionary in the following way as well:

dict1 = { 'abc': 456 };
dict2 = { 'abc': 123, 98.6: 37 };
dict['Age'] = 8; # update existing entry
dict['School'] = "DPS School"; # Add new ent
Each key is separated from its value by a colon (:), the items are separated by commas, and the whole
thing is enclosed in curly braces. An empty dictionary without any items is written with just two 
curly braces, like this: {}.

Accessing Values in Dictionary:
*****************************8**
print "dict['Name']: ", dict['Name'];
print "dict['Age']: ", dict['Age'];

Delete Dictionary Elements:
*******************************
del dict['Name']; # remove entry with key 'Name'
dict.clear();     # remove all entries in dict
del dict ;        # delete entire dictionary

Key properties :
***************************
a) More than one entry per key not allowed. Which means no duplicate key is allowed. When duplicate keys 
encountered during assignment, the last assignment wins. Following is a simple example:



4) Sets :
The sets module provides classes for constructing and manipulating unordered collections of unique elements.
Common uses include membership testing, removing duplicates from a sequence, and computing standard math
operations on sets such as intersection, union, difference, and symmetric difference

>>> from sets import Set
>>> engineers = Set(['John', 'Jane', 'Jack', 'Janice'])
>>> programmers = Set(['Jack', 'Sam', 'Susan', 'Janice'])
>>> managers = Set(['Jane', 'Jack', 'Susan', 'Zack'])
>>> employees = engineers | programmers | managers           # union
>>> engineering_management = engineers & managers            # intersection
>>> fulltime_management = managers - engineers - programmers # difference
>>> engineers.add('Marvin')                                  # add element

Spatialnet use of set 
# scan for referenced poles (strip off the 'ST' from start of ID as not present in test db)
		referenced_pole_ids = set([staging_ent.attributes["POLE_ID"][2:]
								for staging_ent in layer_entities_map.get("Drops",[]) 
								if staging_ent.attributes.get("POLE_ID")])
here a set of unique pole ids referenced from a Drops can be drawn up 


Functions:
===================================================================================================
In python the functions are defined with def

def fun(a,b):
	c = a+b
	return c
d = fun(2,3)

default Function definition is here
	def printinfo( name, age = 35 ):

Variable-length arguments:
	def printinfo( arg1, *vartuple ):
		for var in vartuple:
      print var
	return;
	
multiple argument 
***************************************************************************************************
def manyArgs(*arg):
  print "I was called with", len(arg), "arguments:", arg

>>> manyArgs(1)
I was called with 1 arguments: (1,)
>>> manyArgs(1, 2,3)
I was called with 3 arguments: (1, 2, 3)	

j_txt = _("jobs: ") 

Single Lone Underscore (_)
==================================================
This is typically used in 3 cases:

In the interpreter: The _ name points to the result of the last executed statement in an interactive interpreter session. This was first done by the standard CPython interpreter, and others have followed too.

>>> _
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name '_' is not defined
>>> 42
>>> _
42
>>> 'alright!' if _ else ':('
'alright!'
>>> _
'alright!'
As a name: This is somewhat related to the previous point. _ is used as a throw-away name. This will allow the next person reading your code to know that, by convention, a certain name is assigned but not intended to be used. 
For instance, you may not be interested in the actual value of a loop counter:

n = 42
for _ in range(n):
    do_something()

So overe here we dont care what number the loop is currently at we ajuts need to do something for 42 times and this saves 
n extra variable 
i18n: One may also see _ being used as a function. In that case, it is often the name used for the function that does internationalisation and localisation string translation lookups. This seems to have originated from and follow the corresponding C convention. For instance, as seen in the Django documentation for translation, you may have:

from django.utils.translation import ugettext as _
from django.http import HttpResponse

def my_view(request):
    output = _("Welcome to my site.")
    return HttpResponse(output)
The second and third purposes can conflict, so one should avoid using _ as a throw-away name in any code block that also uses it for i18n lookup and translation.
Difference between _, __ and __xx__ in Python
==================================================
When learning Python many people don't really understand why so much underlines in the beginning of the methods, sometimes even in the end like __this__! I've already had to explain it so many times, it's time to document it.

One underline in the beginning
Python doesn't have real private methods, so one underline in the beginning of a method or attribute means you shouldn't access this method, because it's not part of the API. It's very common when using properties:

class BaseForm(StrAndUnicode):
    ...
    
    def _get_errors(self):
        "Returns an ErrorDict for the data provided for the form"
        if self._errors is None:
            self.full_clean()
        return self._errors
    
    errors = property(_get_errors)
This snippet was taken from django source code (django/forms/forms.py). This means errors is a property, and it's part of the API, but the method this property calls, _get_errors, is "private", so you shouldn't access it.

Two underlines in the beginning
This one causes a lot of confusion. It should not be used to mark a method as private, the goal here is to avoid your method to be overridden by a subclass. Let's see an example:

class A(object):
    def __method(self):
        print "I'm a method in A"
    
    def method(self):
        self.__method()
     
a = A()
a.method()
The output here is

$ python example.py 
I'm a method in A
Fine, as we expected. Now let's subclass A and customize __method

class B(A):
    def __method(self):
        print "I'm a method in B"

b = B()
b.method()
and now the output is...

$ python example.py
I'm a method in A
as you can see, A.method() didn't call B.__method() as we could expect. Actually this is the correct behavior for __. So when you create a method starting with __ you're saying that you don't want anybody to override it, it will be accessible just from inside the own class.

How python does it? Simple, it just renames the method. Take a look:

a = A()
a._A__method()  # never use this!! please!
$ python example.py
I'm a method in A
If you try to access a.__method() it won't work either, as I said, __method is just accessible inside the class itself.

Two underlines in the beginning and in the end
When you see a method like __this__, the rule is simple: don't call it. Why? Because it means it's a method python calls,
 not you. Take a look:

>>> name = "igor"
>>> name.__len__()
4
>>> len(name)
4

>>> number = 10
>>> number.__add__(20)
30
>>> number + 20
30
There is always an operator or native function that calls these magic methods. The idea here is to give you the ability 
to override operators in your own classes. Sometimes it's just a hook python calls in specific situations. __init__(), 
for example, is called when the object is created so you can initialize it. __new__() is called to build the instance, and so on...

Here's an example:

class CrazyNumber(object):
    
    def __init__(self, n):
        self.n = n
    
    def __add__(self, other):
        return self.n - other
    
    def __sub__(self, other):
        return self.n + other
    
    def __str__(self):
        return str(self.n)


num = CrazyNumber(10)
print num           # 10
print num + 5       # 5
print num - 20      # 30
Another example:

class Room(object):

    def __init__(self):
        self.people = []

    def add(self, person):
        self.people.append(person)

    def __len__(self):
        return len(self.people)

room = Room()
room.add("Igor")
print len(room)     # 1
The documentation covers all these special methods.

Conclusion
Use _one_underline to mark you methods as not part of the API. Use __two_underlines__ when you're creating 
objects to look like native python objects or you wan't to customize behavior in specific situations. And 
don't use __just_to_underlines, unless you really know what you're doing!






	
Magic functions:
===================================================================================================
These are teh set of functions always surounded by the Underscores
__class__ =  
__name__ = 

 __init__ is not the first thing to get called. Actually, it's a method called __new__, which
 actually creates the instance, then passes any arguments at creation on to the initializer. At the other end of the object's 
 lifespan, there's __del__. Let's take a closer look at these 3 magic methods:

__new__(cls, [...)
__new__ is the first method to get called in an object's instantiation. It takes the class, then any other arguments that it 
will pass along to __init__. __new__ is used fairly rarely, but it does have its purposes, particularly when subclassing an 
immutable type like a tuple or a string.
I don't want to go in to too much detail on __new__ because it's not too useful, but it is covered in great detail in the 
Python docs.
__init__(self, [...)
The initializer for the class. It gets passed whatever the primary constructor was called with (so, for example, if we called

x = SomeClass(10, 'foo'),
__init__ would get passed 10 and 'foo' as arguments. __init__ is almost universally used in Python class definitions.
__del__(self)
If __new__ and __init__ formed the constructor of the object, __del__ is the destructor. It doesn't implement behavior for the
statement del x (so that code would not translate to x.__del__()). Rather, it defines behavior for when an object is garbage 
collected. It can be quite useful for objects that might require extra cleanup upon deletion, like sockets or file objects. 


Lambda Functions
===================================================================================================
Lamda functions are not bound to a name they just use a construct called lambda.
* Lamda function dont have  a return statment it will always have a line which is returned.
* Lamda can directly used without the use assigning it to a variable.

lambda x,y: x + y

this is a sum function 

lambda Functions:
==================================================
Python supports the creation of anonymous functions (i.e. functions that are not bound to a name) at runtime, 
diffrence between two functions
>>> def f (x): return x**2
... 
>>> print f(8)
64
>>> 
>>> g = lambda x: x**2
>>> 
>>> print g(8)
64


>>> def make_incrementor (n): return lambda x: x + n
>>> 
>>> f = make_incrementor(2)
>>> g = make_incrementor(6)
>>> 
>>> print f(42), g(42)
44 48
>>> 
>>> print make_incrementor(22)(33)
55
The above code defines a function "make_inrementor" that creates an anonymous function on the fly and returns it. The returned function increments its argument by the value that was specified when it was created.



No Multiline Lambda in Python: Why not?
===================================================
Look at the following:

map(multilambda x:
      y=x+1
      return y
   , [1,2,3])
Is this a lambda returning (y, [1,2,3]) (thus map only gets one parameter, resulting in an error)?
 Or does it return y? Or is it a syntax error, because the comma on the new line is misplaced? 
 How would Python know what you want?

Within the parens, indentation doesn't matter to python, so you can't unambiguously work with multilines.

This is just a simple one, there's probably more examples.



This is mostly used as argument of other functional concepts in python on a list of values 
g = [2, 18, 9, 22, 17, 24, 8, 12, 27]

1. filter

Filter seperates the list passed by the lamda then elements in a  new array 
 filter(lambda x: x % 3 == 0,g)
 
 >> [18, 9, 24, 12, 27]
 
 
 
2. map

map will do a set of operations on each of the elements and output it

 map(lambda x: x * 2 + 10, foo)

>> [14, 46, 28, 54, 44, 58, 26, 34, 64]

3. reduce

reduce will do a operation in all the elements at a once and output a result

reduce(lambda x, y: x + y, foo)
>> 139


Modules:
=================================
Creating a module is as simple as creating a file ,and Import it to use it 

Creating a folder Module will include a __init__.py file to make it a Module 





Importing and using of Module methods:
-----------------------------------------
File_mod/File_handler.py    A folder containing a file  having a class test

1) To import this file we 

from File_mod import File_handler

		or
import File_mod.File_handler

2) To Import test class inside the file 

 import File_mod.File_handler.test


Use of if (__name__) to check the Running module is Main or Imported:
--------------------------------------------------------------------
When your script is run by passing it as a command to the Python interpreter,

python myscript.py
all of the code that is at indentation level 0 gets executed.
__name__ is a built-in variable which evaluate to the name of the current module. However, if a module is being 
run directly (as in myscript.py above), then __name__ instead is set to the string "__main__". 
Thus, you can test whether your script is being run directly or being imported by something else by testing

# file one.py
def func():
    print("func() in one.py")

print("top-level in one.py")

if __name__ == "__main__":
    print("one.py is being run directly")
else:
    print("one.py is being imported into another module")

# file two.py
import one

print("top-level in two.py")
one.func()

if __name__ == "__main__":
    print("two.py is being run directly")
else:
    print("two.py is being imported into another module")
Now, if you invoke the interpreter as

python one.py
The output will be

top-level in one.py
one.py is being run directly
If you run two.py instead:

python two.py
You get

top-level in one.py
one.py is being imported into another module
top-level in two.py
func() in one.py
two.py is being run directly
Thus, when module one gets loaded, its __name__ equals "one" instead of __main__.



Global Variables:
=================================
Global vs. Local variables:
Variables that are defined inside a function body have a local scope, and those defined outside have a global scope.

This means that local variables can be accessed only inside the function in which they are declared, whereas global variables can be accessed throughout the program body by all functions. When you call a function, the variables declared inside it are brought into scope. Following is a simple example:

#!/usr/bin/python

total = 0; # This is global variable.
# Function definition is here
def sum( arg1, arg2 ):
   # Add both the parameters and return them."
   total = arg1 + arg2; # Here total is local variable.
   print "Inside the function local total : ", total
   return total;

# Now you can call sum function
sum( 10, 20 );
print "Outside the function global total : ", total 
When the above code is executed, it produces the following result:

Inside the function local total :  30
Outside the function global total :  0



class and objects:
=============================================================================================================
Class declaration in python

class a:
 ... 
 ...

new way of class declaration in Python

class a(object):
// calling the instance of the python
x = a()

now if we print the object 

print a
<__main__.ObjectCreator object at 0x8974f2c>

Classes are objects too.As soon as you use the keyword class, Python executes it and creates an OBJECT
This object (the class) is itself capable of creating objects (the instances), and this is why it's a class.

But still, it's an object, and therefore:

i)you can assign it to a variable
	b =a 
ii)you can copy it
	c(a)

iii)you can add attributes to it
	a.var = 'test'

iv)you can pass it as a function parameter
	print a

Creating classes dynamically
***********************************************************
Since classes are objects, you can create them on the fly, like any object.

First, you can create a class in a function using class:

  >>> def choose_class(name):
  ...     if name == 'foo':
  ...         class Foo(object):
  ...             pass
  ...         return Foo # return the class, not an instance
  ...     else:
  ...         class Bar(object):
  ...             pass
  ...         return Bar
  ...     
  >>> MyClass = choose_class('foo') 
  >>> print(MyClass) # the function returns a class, not an instance
  <class '__main__.Foo'>
  >>> print(MyClass()) # you can create an object from this class
  <__main__.Foo object at 0x89c6d4c>

Use of type in class:
****************************************
>>> print(type(ObjectCreator))
<type 'type'>
>>> print(type(ObjectCreator()))
<class '__main__.ObjectCreator'>

type works this way:

  type(name of the class, 
       tuple of the parent class (for inheritance, can be empty), 
       dictionary containing attributes names and values)

	   
	   
	   MyShinyClass = type('MyShinyClass', (), {}) # returns a class object
	  

What are metaclasses?
************************
Metaclasses are the 'stuff' that creates classes.
metaclasses are what create these objects. They are the classes' classes, you can picture them this way:

  MyClass = MetaClass()
  MyObject = MyClass()
You've seen that type lets you do something like this:

  MyClass = type('MyClass', (), {})
It's because the function type is in fact a metaclass. type is the metaclass Python uses to create all classes behind the scenes.

__class___ Atribute :
**************************
Class gives the class name of the type is followed up with 
name = 'bob'
  >>> name.__class__
  <type 'str'>
 
c = Foo()
c.__class__
>><class '__main__.Foo'>


now what is __class__.__class__ ie class of class which is metaclass
c.__class__.__class__
>><type 'type'>
  
The __metaclass__ attribute:
***************************************
You can add a __metaclass__ attribute when you write a class:

class Foo(object):
  __metaclass__ = something...
  [...]
If you do so, Python will use the metaclass to create the class Foo.

Careful, it's tricky.

You write class Foo(object) first, but the class object Foo is not created in memory yet.
Python will look for __metaclass__ in the class definition. If it finds it, it will use it 
to create the object class Foo. If it doesn't, it will use type to create the class.

Why the hell would you use metaclasses?
Now the big question. Why would you use some obscure error prone feature?

Well, usually you don't:

Metaclasses are deeper magic than 99% of users should ever worry about. If you wonder whether you need them, you don't (the people who actually need them know with certainty that they need them, and don't need an explanation about why).

Python Guru Tim Peters

The main use case for a metaclass is creating an API. A typical example of this is the Django ORM.

It allows you to define something like this:

  class Person(models.Model):
    name = models.CharField(max_length=30)
    age = models.IntegerField()
But if you do this:

  guy = Person(name='bob', age='35')
  print(guy.age)
It won't return an IntegerField object. It will return an int, and can even take it directly from the database.

This is possible because models.Model defines __metaclass__ and it uses some magic that will turn the Person you 
just defined with simple statements into a complex hook to a database field.

Django makes something complex look simple by exposing a simple API and using metaclasses, recreating code from
 this API to do the real job behind the scenes.
 
 
 
 
Magical methods :
===============================================================================

http://www.rafekettler.com/magicmethods.html#intro

Yeild Keyword :
====================================================================================================================
Iterables

When you create a list, you can read its items one by one, and it's called iteration:

>>> mylist = [1, 2, 3]
>>> for i in mylist:
...    print(i)
1
2
3
Mylist is an iterable. When you use a list comprehension, you create a list, and so an iterable:

>>> mylist = [x*x for x in range(3)]
>>> for i in mylist:
...    print(i)
0
1
4
Everything you can use "for... in..." on is an iterable: lists, strings, files... These iterables are handy because you can read them as much as you wish, but you store all the values in memory and it's not always what you want when you have a lot of values.

Generators

Generators are iterators, but you can only iterate over them once. It's because they do not store all the values in memory, they generate the values on the fly:

>>> mygenerator = (x*x for x in range(3))
>>> for i in mygenerator:
...    print(i)
0
1
4
It is just the same except you used () instead of []. BUT, you can not perform for i in mygenerator a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one.

Yield
=============
Yield is a keyword that is used like return, except the function will return a generator.

>>> def createGenerator():
...    mylist = range(3)
...    for i in mylist:
...        yield i*i
...
>>> mygenerator = createGenerator() # create a generator
>>> print(mygenerator) # mygenerator is an object!
<generator object createGenerator at 0xb7555c34>
>>> for i in mygenerator:
...     print(i)
0
1
4
Here it's a useless example, but it's handy when you know your function will return a huge set of values that
 you will only need to read once.

To master yield, you must understand that when you call the function, the code you have written in the function
 body does not run. The function only returns the generator object, this is a bit tricky :-)

Then, your code will be run each time the for uses the generator.

Now the hard part:

The first time the for calls the generator object created from your function, it will run the code in your function 
from the beginning until it hits yield, then it'll return the first value of the loop. Then, each other call will
 run the loop you have written in the function one more time, and return the next value, until there is no value to return.

The generator is considered empty once the function runs but does not hit yield anymore. It can be because the loop 
had come to an end, or because you do not satisfy a "if/else" anymore.

Iterators:
-----------------------------------------------------------
An iterator is nothing more than a container object that implements the iterator
protocol

i = iter([1,2,3,4])
>> i.next()
1
>> i.next()
2
... like that 
the way this is implemented is by using two methods 
a) next, which returns the next item of the container
b) __iter__, which returns the iterator itself

Now we can write our own iterators in the same way just have to implement the __iter__ method 
and next() this next name can be different its not a mandate

class myiter(object):
	def __init__(self,step):
		self.step=step
	def next(self):
		if step ==0:
			raise Exception("Ended")
		step -=1
		return self.step
	def __iter__(self):
		"""return the the iteratoe itself"""
		return self
		
>>i =  myiter(5)
>> for el in MyIterator(4):
... print el



		
	
	

Generators :
-------------------------------------------------------------
generators provide an elegant way to write simple and efficient
code for functions that return a list of elements. Based on the yield directive, they
allow you to pause a function and return an intermediate result. The function saves
its execution context and can be resumed later if necessary.

Ex:
def fibonacci():
	a, b = 0, 1
	while True:
		yield b
		a, b = b, a + b
fib = fibonacci()
[fib.next() for i in range(10)]
[3, 5, 8, 13, 21, 34, 55, 89, 144, 233]

This function returns a generator object, a special iterator, which knows how to
save the execution context. It can be called indefinitely, yielding the next element of
the suite each time.

*** when to use 
generators should be considered every time you deal with a
function that returns a sequence or works in a loop. Returning the elements one at a
time can improve the overall performance, when they are passed to another function
for further work.

One step up again it looks like we will be using yeild as expression and 

but makes yield return the value passed. The function can,
therefore, change its behavior depending on the client code. Two other functions
were added to complete this behavior: throw and close. They raise an error into
the generator:
throw allows the client code to send any kind of exception to be raised.
close acts in the same way, but raises a specific exception: GeneratorExit.
In that case, the generator function must raise GeneratorExit again, or
StopIteration.
Therefore, a typical template for a generator would look like the following:
>>> def my_generator():
... try:
... yield 'something'
... except ValueError:
... yield 'dealing with the exception'
... finally:
... print "ok let's clean"
...
>>> gen = my_generator()
>>> gen.next()
'something'
>>> gen.throw(ValueError('mean mean mean'))
'dealing with the exception'
>>> gen.close()
ok let's clean
>>> gen.next()
Traceback (most recent
The itertools Module
================================================================================
When iterators were added in Python, a new module was provided to implement
common patterns.

1) islice: 
------------------
One can use islice every time to extract data located in a particular position in a
stream.

itertools.islice(iterable, start, stop[, step])
# islice('ABCDEFG', 2) --> A B
# islice('ABCDEFG', 2, 4) --> C D
# islice('ABCDEFG', 2, None) --> C D E F G
# islice('ABCDEFG', 0, None, 2) --> A C E G

Practicle uses:
This can be a file in a special format using records for instance, or a stream
that presents data encapsulated with metadata, like a SOAP envelope, for example.
In that case, islice can be seen as a window that slides over each line of data

2) tee:
--------------------
An iterator consumes the sequence it works with. There is no turning back. tee
provides a pattern to run several iterators over a sequence. This helps us to run over
the data again, if provided with the information of the first run

>>> import itertools
>>> def with_head(iterable, headsize=1):
... a, b = itertools.tee(iterable)
... return list(itertools.islice(a, headsize)), b
...
>>> with_head(seq)
([1], <itertools.tee object at 0x100c698>)
>>> with_head(seq, 4)
([1, 2, 3, 4], <itertools.tee object at 0x100c670>)
In this function, if two iterators are generated with tee, then the first one is used
with islice to get the first headsize elements of the iteration, and return them as
a flat list. The second element returned is a fresh iterator that can be used to perform
work over the whole sequence.

3) groupby: The uniq Iterator
------------------------------------
 It is able to group the duplicate elements from an iterator, as long as they are adjacent. A function can
be given to the function for it to compare the elements
Just a few lines are necessary with groupby to obtain RLE:
>>> from itertools import groupby
>>> def compress(data):
... return ((len(list(group)), name)
... for name, group in groupby(data))
...
>>> def decompress(data):
... return (car * size for size, car in data)
...
>>> list(compress('get uuuuuuuuuuuuuuuuuup'))
[(1, 'g'), (1, 'e'), (1, 't'), (1, ' '),
(18, 'u'), (1, 'p')]
>>> compressed = compress('get uuuuuuuuuuuuuuuuuup')
>>> ''.join(decompress(compressed))
'get uuuuuuuuuuuuuuuuuup

These function are used to make utilities for a ode libarary 
 # [k for k, g in groupby('AAAABBBCCDAABBB')] --> A B C D A B
 # [list(g) for k, g in groupby('AAAABBBCCD')] --> AAAA BBB CC D
 
Others are:
------------------------------
Infinite Iterators:
# count(10) --> 10 11 12 13 14 ...
# count(2.5, 0.5) -> 2.5 3.0 3.5 ...
# cycle('ABCD') --> A B C D A B C D A B C D ...
# repeat(10, 3) --> 10 10 10
Iterators terminating on the shortest input sequence:
# chain('ABC', 'DEF') --> A B C D E F
# compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F
#ifilter(lambda x: x%2, range(10)) --> 1 3 5 7 9
# imap(pow, (2,3,10), (5,2,3)) --> 32 9 1000   (2P5,)
# izip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-
Combinatoric generators:
# product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy
# product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111
# permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC
# permutations(range(3)) --> 012 021 102 120 201 210
# combinations('ABCD', 2) --> AB AC AD BC BD CD
# combinations(range(4), 3) --> 012 013 023 123

repr in python :
==================================================
Module provides a means for producing object representations with limits on the size of the resulting strings. This is 
used in the Python debugger and may be useful in other contexts 

>>> x = 'foo'
>>> x
'foo'
So the name x is attached to 'foo' string. When you call for example repr(x) the iterpreter put 'foo' instead of x and
then calls repr('foo').

>>> repr(x)
"'foo'"
>>> x.__repr__()
"'foo'"
repr actually calls a magic method __repr__ of x, which gives a string containing the representation of the value 'foo'
assigned to x. So it returns 'foo' inside the string "" resulting in "'foo'". The idea of repr is to give a string which
contains a series of symbols which we can type in the interpreter and get the same value which was sent as an argument to repr.

>>> eval("'foo'")
'foo'
When we call eval("'foo'"), it's the same as we type 'foo' in the interpreter. It's as we directly type the contents of the outer string "" in the interpreter.

>>> eval('foo')

Traceback (most recent call last):
  File "<pyshell#5>", line 1, in <module>
    eval('foo')
  File "<string>", line 1, in <module>
NameError: name 'foo' is not defined
If we call eval('foo'), it's the same as we type foo in the interpreter. But there is no foo variable an the exception is raised.

>>> str(x)
'foo'
>>> x.__str__()
'foo'
>>> 


difference between __str__ and __repr__ 
-----------------------------------------:
First, let me reiterate the main points in Alex’s post:

The default implementation is useless (it’s hard to think of one which wouldn’t be, but yeah)
__repr__ goal is to be unambiguous
__str__ goal is to be readable
Container’s __str__ uses contained objects’ __repr__
Default implementation is useless

This is mostly a surprise because Python’s defaults tend to be fairly useful. However, in this case, having a default
for __repr__ which would act like:

return "%s(%r)" % (self.__class__, self.__dict__)
would have been too dangerous (for example, too easy to get into infinite recursion if objects reference each other). 
So Python cops out. Note that there is one default which is true: if __repr__ is defined, and __str__ is not, the object 
will behave as though __str__=__repr__.

This means, in simple terms: almost every object you implement should have a functional __repr__ that’s usable for 
understanding the object. Implementing __str__ is optional: do that if you need a “pretty print” functionality
(for example, used by a report generator).

The goal of __repr__ is to be unambiguous

Let me come right out and say it — I do not believe in debuggers. I don’t really know how to use any debugger, 
and have never used one seriously. Furthermore, I believe that the big fault in debuggers is their basic nature — most 
failures I debug happened a long long time ago, in a galaxy far far away. This means that I do believe, with religious fervor, 
in logging. Logging is the lifeblood of any decent fire-and-forget server system. Python makes it easy to log: with maybe 
some project specific wrappers, all you need is a

log(INFO, "I am in the weird function and a is", a, "and b is", b, "but I got a null C — using default", default_c)
But you have to do the last step — make sure every object you implement has a useful repr, so code like that can just work.
This is why the “eval” thing comes up: if you have enough information so eval(repr(c))==c, that means you know everything 
there is to know about c. If that’s easy enough, at least in a fuzzy way, do it. If not, make sure you have enough information about c anyway. I usually use an eval-like format: "MyClass(this=%r,that=%r)" % (self.this,self.that). It does not mean that you can actually construct MyClass, or that those are the right constructor arguments — but it is a useful form to express “this is everything you need to know about this instance”.

Note: I used %r above, not %s. You always want to use repr() [or %r formatting character, equivalently] inside __repr__ 
implementation, or you’re defeating the goal of repr. You want to be able to differentiate MyClass(3) and MyClass("3").

The goal of __str__ is to be readable

Specifically, it is not intended to be unambiguous — notice that str(3)==str("3"). Likewise, if you implement an IP abstraction, having the str of it look like 192.168.1.1 is just fine. When implementing a date/time abstraction, the str can be "2010/4/12 15:35:22", etc. The goal is to represent it in a way that a user, not a programmer, would want to read it. Chop off useless digits, pretend to be some other class — as long is it supports readability, it is an improvement



Reg Expresions:
======================================
import re

The \w = [a-zA-Z0-9_] // All alpha neumeric stuffs and Underline


a = 'My name is ShankarDD  12'

1) Search any 2 any chars after Shankar.

re.search('Shankar\w\w',a).group()  or re.search('Shankar[a-zA-Z0-9_][a-zA-Z0-9_]',a).group()

>> ShankarDD

For any digits use the \d symbol 



2) Match a symbol at the end ^/start $ of a word



re.search('Shankar[^a-zA-Z0-9_][^a-zA-Z0-9_]',a).group()


>> ShankarDD


3) // is used to match a /








4) Finding a email ID :

str = abc@google.com


	match = re.search('([\w.-]+)@([\w.-]+)', str)


\w is match for [^a-zA-Z0-9_]
. - is also added to the email usernme search

So the () @ () will devide the search in 2 groups divided b


So the ([\w.-]+) wil separate the user name with domain 

match.group(1)= abc
match.group(2)= google.com

--------------------------------------------------------------------------------------------|
Method/Attribute|     Purpose								    |
group()		|	Return the string matched by the RE				    |
start()		|	Return the starting position of the match			    |
end()		|	Return the ending position of the match				    |
span()		|	Return a tuple containing the (start, end) positions of the match   |
--------------------------------------------------------------------------------------------|


5)  Group match :


ating White Spaces from a Line Groupp search by Split or by find all:

line = 'test is all done '

pattern_space = re.split("(?:(?:[^a-zA-Z]+')|(?:'[^a-zA-Z]+))|(?:[^a-zA-Z']+)", line)
pattern_space = re.compile("([\w][\w]*'?\w?)").findall(line)


find all will return you a tuples of all  the matching componenst


Ex:
>>> p = re.compile('\d+')
>>> p.findall('12 drummers drumming, 11 pipers piping, 10 lords a-leaping')
['12', '11', '10']

Split :
----------
Split string by the occurrences of pattern. If capturing parentheses are used in pattern, then the text 
f all groups in the pattern are also returned as part of the resulting list. If maxsplit is nonzero, at
most maxsplit splits occur, and the remainder of the string is returned as the final element of the list.





Greedy vs. Non-Greedy:
================================





Exception Handling:
==============================

raising the exceptions :

def _check_parents_equal(self, other):
        if not self._parents_equal(other):
            raise TypeError(
                'This operation is valid only for enum values of the same type')
                
                


catching it exception passing it for another try:

def __getitem__(cls, other):
        try:
            _check_parents_equal(self, other)
        except TypeError:
            pass
        try:
            return cls._enums_by_str[name]
        except KeyError:
            return cls._enums_by_int[name]



Decorators:
=================================
ython's functions are objects
To understand decorators, you must first understand that functions are objects in Python. This has important consequences. Let's see why with a simple example :

def shout(word="yes"):
    return word.capitalize()+"!"

print shout()
# outputs : 'Yes!'

# As an object, you can assign the function to a variable like any
# other object 

scream = shout

# Notice we don't use parentheses: we are not calling the function, we are
# putting the function "shout" into the variable "scream". 
# It means you can then call "shout" from "scream":

print scream()
# outputs : 'Yes!'

# More than that, it means you can remove the old name 'shout', and
# the function will still be accessible from 'scream'

del shout
try:
    print shout()
except NameError, e:
    print e
    #outputs: "name 'shout' is not defined"

print scream()
# outputs: 'Yes!'
OK, keep that in mind, we are going back to it soon. Another interesting property of Python functions is they can be defined... inside another function!

def talk():

    # You can define a function on the fly in "talk" ...
    def whisper(word="yes"):
        return word.lower()+"..."

    # ... and use it right away!

    print whisper()

# You call "talk", that defines "whisper" EVERY TIME you call it, then
# "whisper" is called in "talk". 
talk()
# outputs: 
# "yes..."

# But "whisper" DOES NOT EXIST outside "talk":

try:
    print whisper()
except NameError, e:
    print e
    #outputs : "name 'whisper' is not defined"*
    
    
Functions references:
===========================
OK, still here? Now the fun part, you've seen that functions are objects and therefore:

can be assigned to a variable;
can be defined in another function.
Well, that means that a function can return another function :-) Have a look:

def getTalk(type="shout"):

    # We define functions on the fly
    def shout(word="yes"):
        return word.capitalize()+"!"

    def whisper(word="yes") :
        return word.lower()+"...";

    # Then we return one of them
    if type == "shout":
        # We don't use "()", we are not calling the function,
        # we are returning the function object
        return shout  
    else:
        return whisper

# How do you use this strange beast?

# Get the function and assign it to a variable
	talk = getTalk()      

# You can see that "talk" is here a function object:
	print talk
#outputs : <function shout at 0xb7ea817c>

# The object is the one returned by the function:
	print talk()
#outputs : Yes!

# And you can even use it directly if you feel wild:
	print getTalk("whisper")()
#outputs : yes...
But wait, there is more. If you can return a function, then you can pass one as a parameter:

def doSomethingBefore(func): 
    print "I do something before then I call the function you gave me"
    print func()

	doSomethingBefore(scream)
#outputs: 
#I do something before then I call the function you gave me
#Yes!
Well, you just have everything needed to understand decorators. You see, decorators are wrappers which means that they let you execute code before and after the function they decorate without the need to modify the function itself.


Passing Multiple Arguments to a Function at a shot :
==============================================================================================
def test_var_args_call(arg1, arg2, arg3):
    print "arg1:", arg1
    print "arg2:", arg2
    print "arg3:", arg3


Passing as a Tuple: Just create a tuple with the arguments and Pass it in the definations 

args = ("two", 3)
test_var_args_call(1, *args)

passing as a Dictionary:  will Similarly just keep the names same of the keys with the args in the function 

kwargs = {"arg3": 3, "arg2": "two"}
test_var_args_call(1, **kwargs)


Handcrafted decorators
==================================================================================================
How you would do it manually:

# A decorator is a function that expects ANOTHER function as parameter
def my_shiny_new_decorator(a_function_to_decorate):

    # Inside, the decorator defines a function on the fly: the wrapper.
    # This function is going to be wrapped around the original function
    
    def the_wrapper_around_the_original_function():

        print "Before the function runs"

        # Call the function here (using parentheses) Actual function call
        a_function_to_decorate()

        print "After the function runs"

    # At this point, "a_function_to_decorate" HAS NEVER BEEN EXECUTED.
    # We return the wrapper function we have just created.
    return the_wrapper_around_the_original_function

# Now imagine you create a function you don't want to ever touch again.
def a_stand_alone_function():
    print "I am a stand alone function, don't you dare modify me"

a_stand_alone_function() 
#outputs: I am a stand alone function, don't you dare modify me

Well, you can decorate it to extend its behavior. Just pass it to the decorator, it will wrap it dynamically in 
 any code you want and return you a new function ready to be used:

a_stand_alone_function_decorated = my_shiny_new_decorator(a_stand_alone_function)
a_stand_alone_function_decorated()


#outputs:
 Before the function runs
 I am a stand alone function, don't you dare modify me
 After the function runs
Now, you probably want that every time you call a_stand_alone_function,
a_stand_alone_function_decorated is called instead. That's easy, just overwrite a_stand_alone_function with 
the function returned by my_shiny_new_decorator:


Decorators demystified
The previous example, using the decorator syntax Now to reuse the above decorator created above and 

@my_shiny_new_decorator
def another_stand_alone_function():
    print "Leave me alone"

another_stand_alone_function()  
#outputs:  
 Before the function runs
 Leave me alone
 After the function runs
 
Yes, that's all, it's that simple. @decorator is just a shortcut to:

another_stand_alone_function = my_shiny_new_decorator(another_stand_alone_function)
Decorators are just a pythonic variant of the decorator design pattern. 
There are several classic design patterns embedded in Python to ease development, like iterators.
Of course, you can cumulate decorators:

def bread(func):
    def wrapper():
        print "</''''''\>"
        func()
        print "<\______/>"
    return wrapper

def ingredients(func):
    def wrapper():
        print "#tomatoes#"
        func()
        print "~salad~"
    return wrapper

def sandwich(food="--ham--"):
    print food

sandwich()
#outputs: --ham--
sandwich = bread(ingredients(sandwich))
sandwich()
#outputs:
#</''''''\>
# #tomatoes#
# --ham--
# ~salad~
#<\______/>
Using the Python decorator syntax:

@bread
@ingredients
def sandwich(food="--ham--"):
    print food

sandwich()
#outputs:
#</''''''\>
# #tomatoes#
# --ham--
# ~salad~
#<\______/>
The order you set the decorators MATTERS:

@ingredients
@bread
def strange_sandwich(food="--ham--"):
    print food

strange_sandwich()
#outputs:
##tomatoes#
#</''''''\>
# --ham--
#<\______/>
# ~salad~
Eventually answering the question
As a conclusion, you can easily see how to answer the question:

# The decorator to make it bold
def makebold(fn):
    # The new function the decorator returns
    def wrapper():
        # Insertion of some code before and after
        return "<b>" + fn() + "</b>"
    return wrapper

# The decorator to make it italic
def makeitalic(fn):
    # The new function the decorator returns
    def wrapper():
        # Insertion of some code before and after
        return "<i>" + fn() + "</i>"
    return wrapper

@makebold
@makeitalic
def say():
    return "hello"

print say() 
#outputs: <b><i>hello</i></b>

# This is the exact equivalent to 
def say():
    return "hello"
say = makebold(makeitalic(say))

print say() 
#outputs: <b><i>hello</i></b>
You can now just leave happy, or burn your brain a little bit more and see advanced uses of decorators.

Passing arguments to the decorated function
# It's not black magic, you just have to let the wrapper 
# pass the argument:

def a_decorator_passing_arguments(function_to_decorate):
    def a_wrapper_accepting_arguments(arg1, arg2):
        print "I got args! Look:", arg1, arg2
        function_to_decorate(arg1, arg2)
    return a_wrapper_accepting_arguments

# Since when you are calling the function returned by the decorator, you are
# calling the wrapper, passing arguments to the wrapper will let it pass them to 
# the decorated function

@a_decorator_passing_arguments
def print_full_name(first_name, last_name):
    print "My name is", first_name, last_name

print_full_name("Peter", "Venkman")
# outputs:
#I got args! Look: Peter Venkman
#My name is Peter Venkman
Decorating methods
What's great with Python is that methods and functions are really the same,
except methods expect their first parameter to be a reference to the current object (self).
It means you can build a decorator for methods the same way, just remember to take self in consideration:

def method_friendly_decorator(method_to_decorate):
    def wrapper(self, lie):
        lie = lie - 3 # very friendly, decrease age even more :-)
        return method_to_decorate(self, lie)
    return wrapper


class Lucy(object):

    def __init__(self):
        self.age = 32

    @method_friendly_decorator
    def sayYourAge(self, lie):
        print "I am %s, what did you think?" % (self.age + lie)

l = Lucy()
l.sayYourAge(-3)
#outputs: I am 26, what did you think?
Of course, if you make a very general decorator and want to apply it to any function or method, no matter
its arguments, then just use *args, **kwargs:

def a_decorator_passing_arbitrary_arguments(function_to_decorate):
    # The wrapper accepts any arguments
    def a_wrapper_accepting_arbitrary_arguments(*args, **kwargs):
        print "Do I have args?:"
        print args
        print kwargs
        # Then you unpack the arguments, here *args, **kwargs
        # If you are not familiar with unpacking, check:
        # http://www.saltycrane.com/blog/2008/01/how-to-use-args-and-kwargs-in-python/
        function_to_decorate(*args, **kwargs)
    return a_wrapper_accepting_arbitrary_arguments

@a_decorator_passing_arbitrary_arguments
def function_with_no_argument():
    print "Python is cool, no argument here."

function_with_no_argument()
#outputs
#Do I have args?:
#()
#{}
#Python is cool, no argument here.

@a_decorator_passing_arbitrary_arguments
def function_with_arguments(a, b, c):
    print a, b, c

function_with_arguments(1,2,3)
#outputs
#Do I have args?:
#(1, 2, 3)
#{}
#1 2 3 

@a_decorator_passing_arbitrary_arguments
def function_with_named_arguments(a, b, c, platypus="Why not ?"):
    print "Do %s, %s and %s like platypus? %s" %\
    (a, b, c, platypus)

function_with_named_arguments("Bill", "Linus", "Steve", platypus="Indeed!")
#outputs
#Do I have args ? :
#('Bill', 'Linus', 'Steve')
#{'platypus': 'Indeed!'}
#Do Bill, Linus and Steve like platypus? Indeed!

class Mary(object):

    def __init__(self):
        self.age = 31

    @a_decorator_passing_arbitrary_arguments
    def sayYourAge(self, lie=-3): # You can now add a default value
        print "I am %s, what did you think ?" % (self.age + lie)

m = Mary()
m.sayYourAge()
#outputs
# Do I have args?:
#(<__main__.Mary object at 0xb7d303ac>,)
#{}
#I am 28, what did you think?
Passing arguments to the decorator
Great, now what would you say about passing arguments to the decorator itself? Well this is a bit twisted because
a decorator must accept a function as an argument and therefore, you cannot pass the decorated function arguments 
directly to the decorator.

Before rushing to the solution, let's write a little reminder:

# Decorators are ORDINARY functions
def my_decorator(func):
    print "I am a ordinary function"
    def wrapper():
        print "I am function returned by the decorator"
        func()
    return wrapper

# Therefore, you can call it without any "@"

def lazy_function():
    print "zzzzzzzz"

decorated_function = my_decorator(lazy_function)
#outputs: I am a ordinary function

# It outputs "I am a ordinary function", because that's just what you do:
# calling a function. Nothing magic.

@my_decorator
def lazy_function():
    print "zzzzzzzz"

#outputs: I am a ordinary function
It's exactly the same. "my_decorator" is called. So when you @my_decorator, you are telling Python to call the function 'labeled by the variable "my_decorator"'. It's important, because the label you give can point directly to the decorator... or not! Let's start to be evil!

def decorator_maker():

    print "I make decorators! I am executed only once: "+\
          "when you make me create a decorator."

    def my_decorator(func):

        print "I am a decorator! I am executed only when you decorate a function."

        def wrapped():
            print ("I am the wrapper around the decorated function. "
                  "I am called when you call the decorated function. "
                  "As the wrapper, I return the RESULT of the decorated function.")
            return func()

        print "As the decorator, I return the wrapped function."

        return wrapped

    print "As a decorator maker, I return a decorator"
    return my_decorator

# Let's create a decorator. It's just a new function after all.
new_decorator = decorator_maker()       
#outputs:
#I make decorators! I am executed only once: when you make me create a decorator.
#As a decorator maker, I return a decorator

# Then we decorate the function

def decorated_function():
    print "I am the decorated function."

decorated_function = new_decorator(decorated_function)
#outputs:
#I am a decorator! I am executed only when you decorate a function.
#As the decorator, I return the wrapped function

# Let's call the function:
decorated_function()
#outputs:
#I am the wrapper around the decorated function. I am called when you call the decorated function.
#As the wrapper, I return the RESULT of the decorated function.
#I am the decorated function.
No surprise here. Let's do EXACTLY the same thing, but skipping intermediate variables:

def decorated_function():
    print "I am the decorated function."
decorated_function = decorator_maker()(decorated_function)
#outputs:
#I make decorators! I am executed only once: when you make me create a decorator.
#As a decorator maker, I return a decorator
#I am a decorator! I am executed only when you decorate a function.
#As the decorator, I return the wrapped function.

# Finally:
decorated_function()    
#outputs:
#I am the wrapper around the decorated function. I am called when you call the decorated function.
#As the wrapper, I return the RESULT of the decorated function.
#I am the decorated function.
Let's make it AGAIN, even shorter:

@decorator_maker()
def decorated_function():
    print "I am the decorated function."
#outputs:
#I make decorators! I am executed only once: when you make me create a decorator.
#As a decorator maker, I return a decorator
#I am a decorator! I am executed only when you decorate a function.
#As the decorator, I return the wrapped function.

#Eventually: 
decorated_function()    
#outputs:
#I am the wrapper around the decorated function. I am called when you call the decorated function.
#As the wrapper, I return the RESULT of the decorated function.
#I am the decorated function.
Hey, did you see that? We used a function call with the "@" syntax :-)

So back to decorators with arguments. If we can use functions to generate the decorator on the fly, we can pass arguments to that function, right?

def decorator_maker_with_arguments(decorator_arg1, decorator_arg2):

    print "I make decorators! And I accept arguments:", decorator_arg1, decorator_arg2

    def my_decorator(func):
        # The ability to pass arguments here is a gift from closures.
        # If you are not comfortable with closures, you can assume it's ok,
        # or read: http://stackoverflow.com/questions/13857/can-you-explain-closures-as-they-relate-to-python
        print "I am the decorator. Somehow you passed me arguments:", decorator_arg1, decorator_arg2

        # Don't confuse decorator arguments and function arguments!
        def wrapped(function_arg1, function_arg2) :
            print ("I am the wrapper around the decorated function.\n"
                  "I can access all the variables\n"
                  "\t- from the decorator: {0} {1}\n"
                  "\t- from the function call: {2} {3}\n"
                  "Then I can pass them to the decorated function"
                  .format(decorator_arg1, decorator_arg2,
                          function_arg1, function_arg2))
            return func(function_arg1, function_arg2)

        return wrapped

    return my_decorator

@decorator_maker_with_arguments("Leonard", "Sheldon")
def decorated_function_with_arguments(function_arg1, function_arg2):
    print ("I am the decorated function and only knows about my arguments: {0}"
           " {1}".format(function_arg1, function_arg2))

decorated_function_with_arguments("Rajesh", "Howard")
#outputs:
#I make decorators! And I accept arguments: Leonard Sheldon
#I am the decorator. Somehow you passed me arguments: Leonard Sheldon
#I am the wrapper around the decorated function. 
#I can access all the variables 
#   - from the decorator: Leonard Sheldon 
#   - from the function call: Rajesh Howard 
#Then I can pass them to the decorated function
#I am the decorated function and only knows about my arguments: Rajesh Howard
Here it is, a decorator with arguments. Arguments can be set as variable:

c1 = "Penny"
c2 = "Leslie"

@decorator_maker_with_arguments("Leonard", c1)
def decorated_function_with_arguments(function_arg1, function_arg2):
    print ("I am the decorated function and only knows about my arguments:"
           " {0} {1}".format(function_arg1, function_arg2))

decorated_function_with_arguments(c2, "Howard")
#outputs:
#I make decorators! And I accept arguments: Leonard Penny
#I am the decorator. Somehow you passed me arguments: Leonard Penny
#I am the wrapper around the decorated function. 
#I can access all the variables 
#   - from the decorator: Leonard Penny 
#   - from the function call: Leslie Howard 
#Then I can pass them to the decorated function
#I am the decorated function and only knows about my arguments: Leslie Howard
As you can see, you can pass arguments to the decorator like any function using this trick. You can even use *args, **kwargs if you wish. But remember decorators are called only once. Just when Python imports the script. You can't dynamically set the arguments afterwards. When you do "import x", the function is already decorated, so you can't change anything.

Let's practice: a decorator to decorate a decorator
OK, as a bonus, I'll give you a snippet to make any decorator accept generically any argument. After all, in order to accept arguments, we created our decorator using another function. We wrapped the decorator. Anything else we saw recently that wrapped function? Oh yes, decorators! Let's have some fun and write a decorator for the decorators:

def decorator_with_args(decorator_to_enhance):
    """ 
    This function is supposed to be used as a decorator.
    It must decorate an other function, that is intended to be used as a decorator.
    Take a cup of coffee.
    It will allow any decorator to accept an arbitrary number of arguments,
    saving you the headache to remember how to do that every time.
    """

    # We use the same trick we did to pass arguments
    def decorator_maker(*args, **kwargs):

        # We create on the fly a decorator that accepts only a function
        # but keeps the passed arguments from the maker.
        def decorator_wrapper(func):

            # We return the result of the original decorator, which, after all, 
            # IS JUST AN ORDINARY FUNCTION (which returns a function).
            # Only pitfall: the decorator must have this specific signature or it won't work:
            return decorator_to_enhance(func, *args, **kwargs)

        return decorator_wrapper

    return decorator_maker
It can be used as follows:

# You create the function you will use as a decorator. And stick a decorator on it :-)
# Don't forget, the signature is "decorator(func, *args, **kwargs)"
@decorator_with_args 
def decorated_decorator(func, *args, **kwargs): 
    def wrapper(function_arg1, function_arg2):
        print "Decorated with", args, kwargs
        return func(function_arg1, function_arg2)
    return wrapper

# Then you decorate the functions you wish with your brand new decorated decorator.

@decorated_decorator(42, 404, 1024)
def decorated_function(function_arg1, function_arg2):
    print "Hello", function_arg1, function_arg2

decorated_function("Universe and", "everything")
#outputs:
#Decorated with (42, 404, 1024) {}
#Hello Universe and everything

# Whoooot!
I know, the last time you had this feeling, it was after listening a guy saying: "before understanding recursion, you must first understand recursion". But now, don't you feel good about mastering this?

Best practices while using decorators
They are new as of Python 2.4, so be sure that's what your code is running on.
Decorators slow down the function call. Keep that in mind.
You can not un-decorate a function. There are hacks to create decorators that can be removed but nobody uses them. So once a function is decorated, it's done. For all the code.
Decorators wrap functions, which can make them hard to debug.
Python 2.5 solves this last issue by providing the functools module including functools.wraps that copies the name, module and docstring of any wrapped function to it's wrapper. Fun fact, functools.wraps is a decorator :-)

# For debugging, the stacktrace prints you the function __name__
def foo():
    print "foo"

print foo.__name__
#outputs: foo

# With a decorator, it gets messy    
def bar(func):
    def wrapper():
        print "bar"
        return func()
    return wrapper

@bar
def foo():
    print "foo"

print foo.__name__
#outputs: wrapper

# "functools" can help for that

import functools

def bar(func):
    # We say that "wrapper", is wrapping "func"
    # and the magic begins
    @functools.wraps(func)
    def wrapper():
        print "bar"
        return func()
    return wrapper

@bar
def foo():
    print "foo"

print foo.__name__
#outputs: foo
How can the decorators be useful?
Now the big question: what can I use decorators for? Seem cool and powerful, but a practical example would be great. Well, there are 1000 possibilities. Classic uses are extending a function behavior from an external lib (you can't modify it) or for a debug purpose (you don't want to modify it because it's temporary). You can use them to extends several functions with the same code without rewriting it every time, for DRY's sake. E.g.:

def benchmark(func):
    """
    A decorator that prints the time a function takes
    to execute.
    """
    import time
    def wrapper(*args, **kwargs):
        t = time.clock()
        res = func(*args, **kwargs)
        print func.__name__, time.clock()-t
        return res
    return wrapper


def logging(func):
    """
    A decorator that logs the activity of the script.
    (it actually just prints it, but it could be logging!)
    """
    def wrapper(*args, **kwargs):
        res = func(*args, **kwargs)
        print func.__name__, args, kwargs
        return res
    return wrapper


def counter(func):
    """
    A decorator that counts and prints the number of times a function has been executed
    """
    def wrapper(*args, **kwargs):
        wrapper.count = wrapper.count + 1
        res = func(*args, **kwargs)
        print "{0} has been used: {1}x".format(func.__name__, wrapper.count)
        return res
    wrapper.count = 0
    return wrapper

@counter
@benchmark
@logging
def reverse_string(string):
    return str(reversed(string))

print reverse_string("Able was I ere I saw Elba")
print reverse_string("A man, a plan, a canoe, pasta, heros, rajahs, a coloratura, maps, snipe, percale, macaroni, a gag, a banana bag, a tan, a tag, a banana bag again (or a camel), a crepe, pins, Spam, a rut, a Rolo, cash, a jar, sore hats, a peon, a canal: Panama!")

#outputs:
#reverse_string ('Able was I ere I saw Elba',) {}
#wrapper 0.0
#wrapper has been used: 1x 
#ablE was I ere I saw elbA
#reverse_string ('A man, a plan, a canoe, pasta, heros, rajahs, a coloratura, maps, snipe, percale, macaroni, a gag, a banana bag, a tan, a tag, a banana bag again (or a camel), a crepe, pins, Spam, a rut, a Rolo, cash, a jar, sore hats, a peon, a canal: Panama!',) {}
#wrapper 0.0
#wrapper has been used: 2x
#!amanaP :lanac a ,noep a ,stah eros ,raj a ,hsac ,oloR a ,tur a ,mapS ,snip ,eperc a ,)lemac a ro( niaga gab ananab a ,gat a ,nat a ,gab ananab a ,gag a ,inoracam ,elacrep ,epins ,spam ,arutaroloc a ,shajar ,soreh ,atsap ,eonac a ,nalp a ,nam A
Of course the good thing with decorators is that you can use them right away on almost anything without rewriting. DRY, I said:

@counter
@benchmark
@logging
def get_random_futurama_quote():
    import httplib
    conn = httplib.HTTPConnection("slashdot.org:80")
    conn.request("HEAD", "/index.html")
    for key, value in conn.getresponse().getheaders():
        if key.startswith("x-b") or key.startswith("x-f"):
            return value
    return "No, I'm ... doesn't!"

print get_random_futurama_quote()
print get_random_futurama_quote()

#outputs:
#get_random_futurama_quote () {}
#wrapper 0.02
#wrapper has been used: 1x
#The laws of science be a harsh mistress.
#get_random_futurama_quote () {}
#wrapper 0.01
#wrapper has been used: 2x
#Curse you, merciful Poseidon!
Python itself provides several decorators: property, staticmethod, etc. Django use decorators to manage caching and view permissions. Twisted to fake inlining asynchronous functions calls. This really is a large playground.

EDIT: given the success of this answer, and people asking me to do the same with metaclasses, I did.
The common patterns for decorators are:
Argument checking
Caching
Proxy
Context provider

1. Argument checking
Checking the arguments that a function receives or returns can be useful when it is
executed in a specific context. For example, if a function is to be called through
XML-RPC, Python will not be able to directly provide its full signature as in
the statically-typed languages.(to check the datatypes of argument wen pass/ret to a function)

A decorator can be used to fixed the allowed type of user defined types fixed a class which implemnets 
a decorator
# Dict to store the 
rpc_info = {} # dictionary of function name and tuple of Arguments 
def xmlrpc(in=(),out=(type(None)): #Wrapper Bread wd default arg tuple as in/out
	#register the Signature allowed 
	func_name= inspect.stack()[1][3] # Get the function name which is calling this decorator
	rpc_info[func_name]=(in,out) # the Global dict is Update Nameand args
	
	def _check_types(elements, types):
		"""Subfunction that checks the types."""
		if len(elements) != len(types):    #
			raise TypeError('argument count is wrong')
		typed = enumerate(izip(elements, types))#(int,string)(int,string)=(int,int)(string,string)
		
		for index, couple in typed:
			arg, of_the_right_type = couple
			if isinstance(arg, of_the_right_type):
				continue
			raise TypeError('arg #%d should be %s' % \(index, of_the_right_type)
	
	#Ingredeints  wrapper sits above sandvich 
	def __xmlrpc(*args): #args = (arg1,arg2)
		#Extracting the Args input
		input_args = arg[1:]
		_check_types(input_args,in) # Lets current arg list wd the fixed type 
		# Now free to call our Sandvich function with arguments
		res = function(*args) ## The function call is the name taken from above
		
		#Check the output as  a list or Tuple 
		if not Type(res) in [list,tuple]
			chck_res= (res,)
		else:
			chck_res=  res
		_check_type(chck_res)
		return res
	return __xmlrpc
return _xmlrpc

Lets write a class that uses this decorator 
class RPC(object):
	@xmlrpc((int,int))
	def meth1(int,int):
		print "received 2 ints as arg n ret type"

	@xmlrpc((int,),(int,))
	def meth2(int):
		print "received 1 ints as arg n ret type as int"
			
lets use the class 
my =RPC()
my.meth1(1,2)  # Runs OK 
my.meth2(1,2) #Throws an error 

2. Caching :
A simple decorator but focuses on those functions whose internal state does not affect the output. Each set of
arguments can be linked to a unique result. So is a good decorator to provide on CPU intensive functions,
the idea over here is to generate a key with args and preserve it for a particular duration 

cache = {} # this maintains a dict of the keys 
def is_obsolute(entry,duration):
	# thsi shuold return the cur time diffrence wd the func entry time 
	return (time.time() - entry['time']) > duration
	
def compute_key(function,args,kw):
	key = pickle.dumps((function.func_name,args,kw))
	return hashlib.sha1(key).hexdigest()
	
def memorize(dur=10):
	def _memorize(function):
		def __memorize(*args,**kw):
			key = compute_key(function,args,kw)
			# check the key exixts or not 
			if (key in cache) and not is_obsolute(cache[key],duration):
				return cache[key]['value']
			# computing 
			result = function(*args,**kw)
			#storing the result 
			cache[key]={'value': result, 'time': time.time()}
			return result
		return __memorize
	return _memorize

@memorize()
def add_it(a,b):
	return a + b
	
add_it(2,2) # 4 

Update the dur @memorize(2)
xml handling :
=================================
file handling:
=================================
regex:
=================================

things to practice:
+++++++++++++++++++++++++++++++++

1. Tuple of list 
==================
first_lst = [('-2.50', 0.49, 0.52), ('-2.00', 0.52, 0.50)]
this is not the correct way and willl throw a generator error
>> print first_lst 
>> <generator object <genexpr> at 0x02261288>

convert the tuple into all floats 
first_lst=[ tuple(float(y) for y in x) for x in first_lst ]

Now the other way (x for x in y) where y is a tuple is all allowed over here 

Change@Me1

2. lamdas list and fetching Values 
====================================
from functools import partial
lambdas = [(lambda : i for i in range(3)]
>>> lambdas[0]()
2
>>> lambdas[1]()
2

Sol: 

The important thing to be understood here is, the functions are created during the evaluation of the list 
comprehension, but the value of i will be evaluated only during the execution of the functions.

So, in your case, you have created three functions and all of them refer i. When those functions are
 invoked at runtime, i will have the value 2, because that was the last value bound to i in the last
 iteration of the for loop.
 
  lambdas = [lambda i=i: i for i in range(3)]
  Use a parameter with default value to bind the current value of i to a local variable. When the lambda
  gets called without an argument, the local variable i is assigned the default value
  
  
  
3. use of Arg and karg best expalined :
==============================================
Soln: 
class Foo():
    def __init__(self, data = False, *args, **kwargs):
        print kwargs, args, data

Foo()
Foo(data = True)
Foo(data = True, data1 = "Welcome")
Foo(True, 1, data1 = "Welcome")
# Foo(True, data1 = "Welcome", 1) # This will throw an error
Output

{} () False
{} () True
{'data1': 'Welcome'} () True
{'data1': 'Welcome'} (1,) True
In this example,

We don't pass a value to data, so default value (False) is assumed
We explicitly pass a value to data, so that value is taken
We explicitly pass a value to data and another keyword argument.
We explicitly pass a value to data, positional parameter and a keyword argument.
This will throw an error because no positional parameter should occur after a keyword argument. Order is very important

4. generator(tuple) vs lsit comprehension
==================================================
[myClass().Function(things) for things in biggerThing]
Function is a method, and it builds a list. The method itself doesn't return anything, but lists get manipulated within.

Now when I change it to a generator ,

(myClass().Function(things) for things in biggerThing)

Wont work 
Soln:

1). map(myClass().Function, biggerThing) 
map(function, iterable, ...)

Apply function to every item of iterable and return a list of the results. If additional iterable arguments are passed, function must take that many arguments and is applied to the items from all iterables in parallel. If one iterable is shorter than another it is assumed to be extended with None items. If function is None, the identity function is assumed; if there are multiple arguments, map() returns a list consisting of tuples containing the corresponding items from all iterables (a kind of transpose operation). The iterable arguments may be a sequence or any iterable object; the result is always a list.


2). 
Generators are evaluated on the fly, as they are consumed. So if you never iterate over a generator, its elements are never evaluated.
So, if you did:

for _ in (myClass().Function(things) for things in biggerThing):
    pass


5.create a dictionary with list comprehension
============================================================

Soln:

d = {key: value for (key, value) in iterable}
Of course, you can use the iterable in any way you want (tuples and lists literals, generator comprehensions, list comprehensions, generator functions, functional composition... feel creative) as long as each element is an iterable itself of two elements:

d = {value: foo(value) for value in sequence if bar(value)}

def key_value_gen(k):
   yield chr(k+65)
   yield chr((k+13)%26+65)
d = dict(map(key_value_gen, range(26)))

6.sort a list of dictionaries by values of the dictionary in Python?
===================================================================
[{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]
sorted by name, should become

[{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]


sol:
newlist = sorted(list_to_be_sorted, key=lambda k: k['name']) 

7.  list to make a dictionary
===================================
a = [1,2,3,4] and I want d = {1:0, 2:0, 3:0, 4:0}

sol:
zip can be usedinsid a dict to make a key value pair
a = [1,2,3,4] and I want d = {1:0, 2:0, 3:0, 4:0}


dict(zip(x ,[0 for x in range(0,len(x))]))
